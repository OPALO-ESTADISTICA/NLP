{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing - V.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/images/turing.png\" alt=\"drawing\" width=\"480\" height=\"320\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Natural Language Processing (NLP)** is a branch of artificial intelligence that allows computers to understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.\n",
    "\n",
    "## Where do we find NLP?\n",
    "* **Information retrieval:** For example, web searching algorithms that use keyword matching. \n",
    "* **Target Ads:** For example, algorithms that understand keywords from what you're looking for in social media and, give recommendations based on that.\n",
    "* **Translators:** For example, Google Translate.\n",
    "* **Speech Recognition:** For example, Siri, Alexa, Hey Google, or live captions.\n",
    "* **Text Summarization:** Algorithms that allow getting a summary out of a text.\n",
    "* **Sentiment Analysis:** reviews, tweets, comments where we try to understand the user's feelings. \n",
    "\n",
    "\n",
    "## NLP Pipeline\n",
    "\n",
    "In all data science processes we have a defined pipeline. In the case of Natural Language Processing, the preprocessing steps differ from how we would approach work with structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/images/nlp_pipeline.png\" alt=\"drawing\" width=\"680\" height=\"620\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider the following steps:\n",
    "\n",
    "**0.** Start with a Question.\n",
    "\n",
    "**1.** Get the raw text and put it in a standard format.\n",
    "\n",
    "**2.** Clean the data (remove punctuation, numbers, standardize text: lowercase text).\n",
    "\n",
    "**3.** Tokenize: Divide text by sentences, or words.\n",
    "\n",
    "**4.** Remove Stop words if needed.\n",
    "\n",
    "**5.** Put text in a Matrix to handle the data better.\n",
    "\n",
    "**6.** Perform EDA.\n",
    "\n",
    "**7.** Apply Data Science techniques such as sentiment analysis, modelling, etc. \n",
    "\n",
    "**8.** Get conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification in NLP - Twitter Dataset \n",
    "\n",
    "Twitter is a well-known microblog service from which public data can be collected via APIs. NLTK's twitter corpus currently contains a sample of 20k Tweets retrieved from the Twitter Streaming API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Download nltk data\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import twitter_samples \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tag import pos_tag_sents\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Where are the files that we're downloading?**\n",
    "\n",
    "By running `nltk.download('twitter_samples')`, we are downloading the twitter samples in json files.  \n",
    "We can get their specific location and we'll find these files in our computers anytime.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TwitterCorpusReader in 'C:\\\\Users\\\\USUARIO\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\twitter_samples'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many JSON files do exist in the corpus twitter_samples?**\n",
    "\n",
    "Use the `twitter_samples.fileids()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From `twitter_samples` we're getting Positive and Negative tuits.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive :  #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :) \n",
      "\n",
      "Negative :  hopeless for tmr :(\n"
     ]
    }
   ],
   "source": [
    "#Checking the first element:\n",
    "print('Positive : ',twitter_samples.strings('positive_tweets.json')[0],'\\n')\n",
    "print('Negative : ',twitter_samples.strings('negative_tweets.json')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also apply the Tokenized() method to divide the text by words and other characteres if needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive :  ['#FollowFriday', '@France_Inte', '@PKuchly57', '@Milipol_Paris', 'for', 'being', 'top', 'engaged', 'members', 'in', 'my', 'community', 'this', 'week', ':)'] \n",
      "\n",
      "Negative :  ['hopeless', 'for', 'tmr', ':(']\n"
     ]
    }
   ],
   "source": [
    "print('Positive : ',twitter_samples.tokenized('positive_tweets.json')[0],'\\n')\n",
    "print('Negative : ',twitter_samples.tokenized('negative_tweets.json')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can divide the file by each tuit applying the string method with the objective of converting it into a Dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tw = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tw = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many tuits do we have?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets:  5000\n",
      "Negative tweets:  5000\n"
     ]
    }
   ],
   "source": [
    "print('Positive tweets: ',len(positive_tw))\n",
    "print('Negative tweets: ',len(negative_tw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding  the tweets to new DataFrames using Pandas\n",
    "**Creating one dataframe for positive tweets and one for negative tweets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>@chriswiggin3 Chris, that's great to hear :) D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>@RachelLiskeard Thanks for the shout-out :) It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>@side556 Hey!  :)  Long time no talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>@staybubbly69 as Matt would say. WELCOME TO AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>@DanielOConnel18 you could say he will have eg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets\n",
       "0     #FollowFriday @France_Inte @PKuchly57 @Milipol...\n",
       "1     @Lamb2ja Hey James! How odd :/ Please call our...\n",
       "2     @DespiteOfficial we had a listen last night :)...\n",
       "3                                  @97sides CONGRATS :)\n",
       "4     yeaaaah yippppy!!!  my accnt verified rqst has...\n",
       "...                                                 ...\n",
       "4995  @chriswiggin3 Chris, that's great to hear :) D...\n",
       "4996  @RachelLiskeard Thanks for the shout-out :) It...\n",
       "4997            @side556 Hey!  :)  Long time no talk...\n",
       "4998  @staybubbly69 as Matt would say. WELCOME TO AD...\n",
       "4999  @DanielOConnel18 you could say he will have eg...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_tweets = pd.DataFrame(positive_tw, columns= ['tweets'])\n",
    "positive_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hopeless for tmr :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everything in the kids section of IKEA is so c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Hegelbon That heart sliding into the waste ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“@ketchBurning: I hate Japanese call him \"bani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dang starting next week I have \"work\" :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>I wanna change my avi but uSanele :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>MY PUPPY BROKE HER FOOT :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>where's all the jaebum baby pictures :((</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>But but Mr Ahmad Maslan cooks too :( https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>@eawoman As a Hull supporter I am expecting a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets\n",
       "0                                   hopeless for tmr :(\n",
       "1     Everything in the kids section of IKEA is so c...\n",
       "2     @Hegelbon That heart sliding into the waste ba...\n",
       "3     “@ketchBurning: I hate Japanese call him \"bani...\n",
       "4              Dang starting next week I have \"work\" :(\n",
       "...                                                 ...\n",
       "4995               I wanna change my avi but uSanele :(\n",
       "4996                         MY PUPPY BROKE HER FOOT :(\n",
       "4997           where's all the jaebum baby pictures :((\n",
       "4998  But but Mr Ahmad Maslan cooks too :( https://t...\n",
       "4999  @eawoman As a Hull supporter I am expecting a ...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_tweets = pd.DataFrame(negative_tw, columns= ['tweets'])\n",
    "negative_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Tasks\n",
    "\n",
    "We have several preprocessing tasks when analyzing text:\n",
    "\n",
    "- Tokenize\n",
    "- Remove Stop Words\n",
    "- Clean special characters in text\n",
    "- Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by merging the positive and negative tweets into one dataset and give them the tag `pos` or `neg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we can create a new column which will identify the positive and the negative tweets. We will call this new columns `sentiment`. We'll do this to both Dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  \\\n",
       "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...          1   \n",
       "1  @Lamb2ja Hey James! How odd :/ Please call our...          1   \n",
       "2  @DespiteOfficial we had a listen last night :)...          1   \n",
       "3                               @97sides CONGRATS :)          1   \n",
       "4  yeaaaah yippppy!!!  my accnt verified rqst has...          1   \n",
       "\n",
       "  sentiment_description  \n",
       "0              positive  \n",
       "1              positive  \n",
       "2              positive  \n",
       "3              positive  \n",
       "4              positive  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_tweets['sentiment'] = 1\n",
    "positive_tweets['sentiment_description'] = 'positive'\n",
    "\n",
    "negative_tweets['sentiment'] = 0\n",
    "negative_tweets['sentiment_description'] = 'negative'\n",
    "\n",
    "#How does the positive tweets look like?\n",
    "positive_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hopeless for tmr :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everything in the kids section of IKEA is so c...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Hegelbon That heart sliding into the waste ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“@ketchBurning: I hate Japanese call him \"bani...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dang starting next week I have \"work\" :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  \\\n",
       "0                                hopeless for tmr :(          0   \n",
       "1  Everything in the kids section of IKEA is so c...          0   \n",
       "2  @Hegelbon That heart sliding into the waste ba...          0   \n",
       "3  “@ketchBurning: I hate Japanese call him \"bani...          0   \n",
       "4           Dang starting next week I have \"work\" :(          0   \n",
       "\n",
       "  sentiment_description  \n",
       "0              negative  \n",
       "1              negative  \n",
       "2              negative  \n",
       "3              negative  \n",
       "4              negative  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How does the negative tweets look like?\n",
    "negative_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a copy from the positive tweets to a new DataFrame that we will call `tweets`, that way we will add the negative tweets to the end of our new DataFrame, and we will have all the 10 thousand tweets mixed together, positive and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>@chriswiggin3 Chris, that's great to hear :) D...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>@RachelLiskeard Thanks for the shout-out :) It...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>@side556 Hey!  :)  Long time no talk...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>@staybubbly69 as Matt would say. WELCOME TO AD...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>@DanielOConnel18 you could say he will have eg...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  sentiment  \\\n",
       "0     #FollowFriday @France_Inte @PKuchly57 @Milipol...          1   \n",
       "1     @Lamb2ja Hey James! How odd :/ Please call our...          1   \n",
       "2     @DespiteOfficial we had a listen last night :)...          1   \n",
       "3                                  @97sides CONGRATS :)          1   \n",
       "4     yeaaaah yippppy!!!  my accnt verified rqst has...          1   \n",
       "...                                                 ...        ...   \n",
       "4995  @chriswiggin3 Chris, that's great to hear :) D...          1   \n",
       "4996  @RachelLiskeard Thanks for the shout-out :) It...          1   \n",
       "4997            @side556 Hey!  :)  Long time no talk...          1   \n",
       "4998  @staybubbly69 as Matt would say. WELCOME TO AD...          1   \n",
       "4999  @DanielOConnel18 you could say he will have eg...          1   \n",
       "\n",
       "     sentiment_description  \n",
       "0                 positive  \n",
       "1                 positive  \n",
       "2                 positive  \n",
       "3                 positive  \n",
       "4                 positive  \n",
       "...                    ...  \n",
       "4995              positive  \n",
       "4996              positive  \n",
       "4997              positive  \n",
       "4998              positive  \n",
       "4999              positive  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the copy of the Positive tweets and adding it to a new DataFrame\n",
    "tweets_df = positive_tweets.copy()\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>I wanna change my avi but uSanele :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>MY PUPPY BROKE HER FOOT :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>where's all the jaebum baby pictures :((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>But but Mr Ahmad Maslan cooks too :( https://t...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>@eawoman As a Hull supporter I am expecting a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  sentiment  \\\n",
       "0     #FollowFriday @France_Inte @PKuchly57 @Milipol...          1   \n",
       "1     @Lamb2ja Hey James! How odd :/ Please call our...          1   \n",
       "2     @DespiteOfficial we had a listen last night :)...          1   \n",
       "3                                  @97sides CONGRATS :)          1   \n",
       "4     yeaaaah yippppy!!!  my accnt verified rqst has...          1   \n",
       "...                                                 ...        ...   \n",
       "9995               I wanna change my avi but uSanele :(          0   \n",
       "9996                         MY PUPPY BROKE HER FOOT :(          0   \n",
       "9997           where's all the jaebum baby pictures :((          0   \n",
       "9998  But but Mr Ahmad Maslan cooks too :( https://t...          0   \n",
       "9999  @eawoman As a Hull supporter I am expecting a ...          0   \n",
       "\n",
       "     sentiment_description  \n",
       "0                 positive  \n",
       "1                 positive  \n",
       "2                 positive  \n",
       "3                 positive  \n",
       "4                 positive  \n",
       "...                    ...  \n",
       "9995              negative  \n",
       "9996              negative  \n",
       "9997              negative  \n",
       "9998              negative  \n",
       "9999              negative  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the negative tweets to our new DataFrame \"tweets\".\n",
    "tweets_df = tweets_df.append(negative_tweets, ignore_index = True)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7115</th>\n",
       "      <td>Delph injured already :( #MCFC</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>@JackJcnes text: :( why</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>Vidcon :(((((((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>I still fully intend to write as many game des...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>#ProKabaddi Koel Mallick @YourKoel recites the...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9176</th>\n",
       "      <td>@bbgurrll i miss you too :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>dear haters :) https://t.co/BxqZP6MXgr</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8305</th>\n",
       "      <td>@Y0rgi Wish I could give some to you. I really...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5183</th>\n",
       "      <td>its not the same. :(((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5067</th>\n",
       "      <td>@carliot23 Miss you Boss :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  sentiment  \\\n",
       "7115                     Delph injured already :( #MCFC          0   \n",
       "5542                            @JackJcnes text: :( why          0   \n",
       "7907                                  Vidcon :(((((((((          0   \n",
       "518   I still fully intend to write as many game des...          1   \n",
       "514   #ProKabaddi Koel Mallick @YourKoel recites the...          1   \n",
       "...                                                 ...        ...   \n",
       "9176                        @bbgurrll i miss you too :(          0   \n",
       "2649             dear haters :) https://t.co/BxqZP6MXgr          1   \n",
       "8305  @Y0rgi Wish I could give some to you. I really...          0   \n",
       "5183                           its not the same. :(((((          0   \n",
       "5067                        @carliot23 Miss you Boss :(          0   \n",
       "\n",
       "     sentiment_description  \n",
       "7115              negative  \n",
       "5542              negative  \n",
       "7907              negative  \n",
       "518               positive  \n",
       "514               positive  \n",
       "...                    ...  \n",
       "9176              negative  \n",
       "2649              positive  \n",
       "8305              negative  \n",
       "5183              negative  \n",
       "5067              negative  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = tweets_df.sample(frac = 1)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delph injured already :( #MCFC</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@JackJcnes text: :( why</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vidcon :(((((((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I still fully intend to write as many game des...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ProKabaddi Koel Mallick @YourKoel recites the...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>@bbgurrll i miss you too :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>dear haters :) https://t.co/BxqZP6MXgr</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>@Y0rgi Wish I could give some to you. I really...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>its not the same. :(((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>@carliot23 Miss you Boss :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  sentiment  \\\n",
       "0                        Delph injured already :( #MCFC          0   \n",
       "1                               @JackJcnes text: :( why          0   \n",
       "2                                     Vidcon :(((((((((          0   \n",
       "3     I still fully intend to write as many game des...          1   \n",
       "4     #ProKabaddi Koel Mallick @YourKoel recites the...          1   \n",
       "...                                                 ...        ...   \n",
       "9995                        @bbgurrll i miss you too :(          0   \n",
       "9996             dear haters :) https://t.co/BxqZP6MXgr          1   \n",
       "9997  @Y0rgi Wish I could give some to you. I really...          0   \n",
       "9998                           its not the same. :(((((          0   \n",
       "9999                        @carliot23 Miss you Boss :(          0   \n",
       "\n",
       "     sentiment_description  \n",
       "0                 negative  \n",
       "1                 negative  \n",
       "2                 negative  \n",
       "3                 positive  \n",
       "4                 positive  \n",
       "...                    ...  \n",
       "9995              negative  \n",
       "9996              positive  \n",
       "9997              negative  \n",
       "9998              negative  \n",
       "9999              negative  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.reset_index(drop = True, inplace= True)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "**1.** Why do we use `df.sample()`? \n",
    "  The method from Pandas, `df.sample()`, is used to generate a sample random row or column from the function caller data frame.\n",
    "\n",
    "\n",
    "**2.** If any of your columns don't have the same name, your DataFrame will look not organized, you can givi it a try and check what exactly happens.\n",
    "\n",
    "**3.** Did you notice how important is checking every step? Paying attention to the index of our DataFrame was very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d9fdc7d208>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's visualize and verify that our data is consistent.\n",
    "\n",
    "plt.figure(figsize=(5,3.5)) #this fixes the size ratio\n",
    "sns.set() #this gives it more style\n",
    "sns.histplot(data=tweets_df, x='sentiment_description', palette=\"BuGn_r\", hue = 'sentiment', shrink=.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and standardizing the text data:\n",
    "1. Lowercase\n",
    "2. Remove extra white spaces.\n",
    "3. Remove URL's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase:\n",
    "\n",
    "We use `str.lower()` to convert all characters from our tweets to lowercase. \n",
    "Let's remember, **[string](https://docs.python.org/3/library/stdtypes.html#string-methods)** has many different **methods** to handle text which belongs to the different **[Text Processing Services](https://docs.python.org/3/library/text.html#textservices)** of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/images/string_methods.png\" alt=\"drawing\" width=\"750\" height=\"550\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delph injured already :( #mcfc</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jackjcnes text: :( why</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vidcon :(((((((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i still fully intend to write as many game des...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#prokabaddi koel mallick @yourkoel recites the...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>onkey!!! :-* :-*  &amp;gt;,,&amp;lt;!! nice edit(?) lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@theguyliner @trishie_d cool. :d</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@mr_sinister0013 thanks for playing #journeyps...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i hate being an adult sometimes :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sometimes the most ordinary things can be made...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  \\\n",
       "0                     delph injured already :( #mcfc          0   \n",
       "1                            @jackjcnes text: :( why          0   \n",
       "2                                  vidcon :(((((((((          0   \n",
       "3  i still fully intend to write as many game des...          1   \n",
       "4  #prokabaddi koel mallick @yourkoel recites the...          1   \n",
       "5  onkey!!! :-* :-*  &gt;,,&lt;!! nice edit(?) lo...          1   \n",
       "6                   @theguyliner @trishie_d cool. :d          1   \n",
       "7  @mr_sinister0013 thanks for playing #journeyps...          1   \n",
       "8                 i hate being an adult sometimes :(          0   \n",
       "9  sometimes the most ordinary things can be made...          1   \n",
       "\n",
       "  sentiment_description  \n",
       "0              negative  \n",
       "1              negative  \n",
       "2              negative  \n",
       "3              positive  \n",
       "4              positive  \n",
       "5              positive  \n",
       "6              positive  \n",
       "7              positive  \n",
       "8              negative  \n",
       "9              positive  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lowercase\n",
    "def convert_lowercase(tweets):\n",
    "    return tweets.lower()\n",
    "\n",
    "tweets_df['tweets'] = tweets_df['tweets'].apply(lambda k: convert_lowercase(k))\n",
    "\n",
    "tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we need to clean the text data that belongs to each tweet. What kind of characteres do you think we need to remove?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding and Removing URL's:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to find out if there are any tweets that contain URL's. After that, we can proceed to remove the URL's from the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "      <th>find_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delph injured already :( #mcfc</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jackjcnes text: :( why</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vidcon :(((((((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i still fully intend to write as many game des...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#prokabaddi koel mallick @yourkoel recites the...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>@bbgurrll i miss you too :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>dear haters :) https://t.co/bxqzp6mxgr</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>@y0rgi wish i could give some to you. i really...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>its not the same. :(((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>@carliot23 miss you boss :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  sentiment  \\\n",
       "0                        delph injured already :( #mcfc          0   \n",
       "1                               @jackjcnes text: :( why          0   \n",
       "2                                     vidcon :(((((((((          0   \n",
       "3     i still fully intend to write as many game des...          1   \n",
       "4     #prokabaddi koel mallick @yourkoel recites the...          1   \n",
       "...                                                 ...        ...   \n",
       "9995                        @bbgurrll i miss you too :(          0   \n",
       "9996             dear haters :) https://t.co/bxqzp6mxgr          1   \n",
       "9997  @y0rgi wish i could give some to you. i really...          0   \n",
       "9998                           its not the same. :(((((          0   \n",
       "9999                        @carliot23 miss you boss :(          0   \n",
       "\n",
       "     sentiment_description  find_url  \n",
       "0                 negative        -1  \n",
       "1                 negative        -1  \n",
       "2                 negative        -1  \n",
       "3                 positive        -1  \n",
       "4                 positive        99  \n",
       "...                    ...       ...  \n",
       "9995              negative        -1  \n",
       "9996              positive        15  \n",
       "9997              negative        -1  \n",
       "9998              negative        -1  \n",
       "9999              negative        -1  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the tweets that contain 'https\n",
    "def find_url(tweets):\n",
    "    return tweets.find('http')\n",
    "\n",
    "tweets_df['find_url'] = tweets_df['tweets'].apply(lambda k: find_url(k))\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1      8335\n",
       " 74       38\n",
       " 73       37\n",
       " 38       34\n",
       " 117      33\n",
       "        ... \n",
       " 122       2\n",
       " 124       1\n",
       " 4         1\n",
       " 130       1\n",
       " 119       1\n",
       "Name: find_url, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['find_url'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we do? We created a column called `find_url` to have a sort of tag for the tweets that contain URL's. These tweets will have numbers equal or bigger than 0 and less or equal to 140."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "      <th>find_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#prokabaddi koel mallick @yourkoel recites the...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>onkey!!! :-* :-*  &amp;gt;,,&amp;lt;!! nice edit(?) lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>well summers over then :( knew it wouldn't las...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>you're gonna be such a good father :( https://...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>remember that unlisted one where he had a hick...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>only one leg on september. so perhaps bb will ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sense of awe :) http://t.co/jtjojcdhwg via @di...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>i'm back :) sorry i had many problems :) http:...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>#climatechange #cc it ain't easy being green i...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>twine is looking great over at diane's place :...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweets  sentiment  \\\n",
       "4   #prokabaddi koel mallick @yourkoel recites the...          1   \n",
       "5   onkey!!! :-* :-*  &gt;,,&lt;!! nice edit(?) lo...          1   \n",
       "24  well summers over then :( knew it wouldn't las...          0   \n",
       "27  you're gonna be such a good father :( https://...          0   \n",
       "28  remember that unlisted one where he had a hick...          1   \n",
       "42  only one leg on september. so perhaps bb will ...          1   \n",
       "50  sense of awe :) http://t.co/jtjojcdhwg via @di...          1   \n",
       "52  i'm back :) sorry i had many problems :) http:...          1   \n",
       "58  #climatechange #cc it ain't easy being green i...          0   \n",
       "60  twine is looking great over at diane's place :...          1   \n",
       "\n",
       "   sentiment_description  find_url  \n",
       "4               positive        99  \n",
       "5               positive       111  \n",
       "24              negative        75  \n",
       "27              negative        38  \n",
       "28              positive        54  \n",
       "42              positive        85  \n",
       "50              positive        16  \n",
       "52              positive        41  \n",
       "58              negative        93  \n",
       "60              positive        48  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_url = range(140)\n",
    "match_url = tweets_df[tweets_df['find_url'].isin(with_url)] \n",
    "match_url.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have to remove URL's out of 1665 tweets**\n",
    "\n",
    "To remove the URL's we will use Regular Expresions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "      <th>find_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delph injured already :( #mcfc</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jackjcnes text: :( why</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vidcon :(((((((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i still fully intend to write as many game des...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#prokabaddi koel mallick @yourkoel recites the...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>onkey!!! :-* :-*  &amp;gt;,,&amp;lt;!! nice edit(?) lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@theguyliner @trishie_d cool. :d</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@mr_sinister0013 thanks for playing #journeyps...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i hate being an adult sometimes :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sometimes the most ordinary things can be made...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  \\\n",
       "0                     delph injured already :( #mcfc          0   \n",
       "1                            @jackjcnes text: :( why          0   \n",
       "2                                  vidcon :(((((((((          0   \n",
       "3  i still fully intend to write as many game des...          1   \n",
       "4  #prokabaddi koel mallick @yourkoel recites the...          1   \n",
       "5  onkey!!! :-* :-*  &gt;,,&lt;!! nice edit(?) lo...          1   \n",
       "6                   @theguyliner @trishie_d cool. :d          1   \n",
       "7  @mr_sinister0013 thanks for playing #journeyps...          1   \n",
       "8                 i hate being an adult sometimes :(          0   \n",
       "9  sometimes the most ordinary things can be made...          1   \n",
       "\n",
       "  sentiment_description  find_url  \n",
       "0              negative        -1  \n",
       "1              negative        -1  \n",
       "2              negative        -1  \n",
       "3              positive        -1  \n",
       "4              positive        99  \n",
       "5              positive       111  \n",
       "6              positive        -1  \n",
       "7              positive        -1  \n",
       "8              negative        -1  \n",
       "9              positive        -1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_urls(tweets):\n",
    "    url_pattern = re.compile(r'http[s]?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', tweets)\n",
    "\n",
    "tweets_df['tweets'] = tweets_df['tweets'].apply(remove_urls)\n",
    "tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confirm that tweets don't contain URL's anymore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "      <th>find_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delph injured already :( #mcfc</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jackjcnes text: :( why</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vidcon :(((((((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i still fully intend to write as many game des...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#prokabaddi koel mallick @yourkoel recites the...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>@bbgurrll i miss you too :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>dear haters :)</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>@y0rgi wish i could give some to you. i really...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>its not the same. :(((((</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>@carliot23 miss you boss :(</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  sentiment  \\\n",
       "0                        delph injured already :( #mcfc          0   \n",
       "1                               @jackjcnes text: :( why          0   \n",
       "2                                     vidcon :(((((((((          0   \n",
       "3     i still fully intend to write as many game des...          1   \n",
       "4     #prokabaddi koel mallick @yourkoel recites the...          1   \n",
       "...                                                 ...        ...   \n",
       "9995                        @bbgurrll i miss you too :(          0   \n",
       "9996                                    dear haters :)           1   \n",
       "9997  @y0rgi wish i could give some to you. i really...          0   \n",
       "9998                           its not the same. :(((((          0   \n",
       "9999                        @carliot23 miss you boss :(          0   \n",
       "\n",
       "     sentiment_description  find_url  \n",
       "0                 negative        -1  \n",
       "1                 negative        -1  \n",
       "2                 negative        -1  \n",
       "3                 positive        -1  \n",
       "4                 positive        -1  \n",
       "...                    ...       ...  \n",
       "9995              negative        -1  \n",
       "9996              positive        -1  \n",
       "9997              negative        -1  \n",
       "9998              negative        -1  \n",
       "9999              negative        -1  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_url(tweets):\n",
    "    return tweets.find('http')\n",
    "\n",
    "tweets_df['find_url'] = tweets_df['tweets'].apply(lambda k: find_url(k))\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets that still contain URL's?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_description</th>\n",
       "      <th>find_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>@httpbethx i packed all my socks for camping s...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>@httpsguitarist fback? :)</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  sentiment  \\\n",
       "1196  @httpbethx i packed all my socks for camping s...          0   \n",
       "3819                          @httpsguitarist fback? :)          1   \n",
       "\n",
       "     sentiment_description  find_url  \n",
       "1196              negative         1  \n",
       "3819              positive         1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_url = range(140)\n",
    "match_url_2 = tweets_df[tweets_df['find_url'].isin(with_url)] \n",
    "print(\"Tweets that still contain URL's?\")\n",
    "match_url_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing emojis and emoticons with words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DS4A bring to us so many emotions, mainly, happiness face_with_tears_of_joysmiling_face_with_sunglasses'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To convert emojis into words:\n",
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMOJI:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text \n",
    "\n",
    "#This is an example:\n",
    "ds4a_text = \"DS4A bring to us so many emotions, mainly, happiness 😂😎\"\n",
    "convert_emojis(ds4a_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert emoticons into words:\n",
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS_EMO:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS_EMO[emot].replace(\",\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "#This is an example:\n",
    "#ds4a_text_2 = \"Data Science has changed my life :D :D :3\"\n",
    "#convert_emoticons(ds4a_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweets_no_emoticons'] = tweets_df['tweets'].apply(convert_emoticons)\n",
    "tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweets_no_emojis'] = tweets_df['tweets_no_emoticons'].apply(convert_emojis)\n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweets_no_emojis'] = tweets_df['tweets_no_emojis'].str.replace('_',' ')\n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(tweets):\n",
    "    mention_pattern = re.compile(r'(@[A-Za-z0-9]+)|[_]|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)')\n",
    "    return mention_pattern.sub(r'', tweets)\n",
    "\n",
    "tweets_df['tweets_no_mentions'] = tweets_df['tweets_no_emojis'].apply(remove_mentions)\n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['new_tweets'] = tweets_df['tweets_no_mentions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's have a new DataFrame \n",
    "new_tweets_df = tweets_df[['new_tweets', 'sentiment', 'sentiment_description']]\n",
    "new_tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing other characteres (punctuation, extra spaces, numbers and special characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(tweet):\n",
    "    tweet = re.sub(\"(@[A-Za-z0–9_]+)\",\"\", tweet)\n",
    "    tweet =\"\".join([char if char not in string.punctuation else \" \" for char in tweet])\n",
    "    tweet = re.sub(' +', ' ', tweet) \n",
    "    tweet = re.sub(\"[0–9]+\",\"\", tweet)\n",
    "    tweet = re.sub(\"[^A-Za-z0–9_. ]+\",\"\",tweet)\n",
    " \n",
    "    return tweet\n",
    "\n",
    "#Creating a new column called 'tweets' that is going to contain our result.\n",
    "new_tweets_df['tweets'] = new_tweets_df['new_tweets'].apply(lambda x: remove_noise(x))\n",
    "\n",
    "# Selecting only the columns that are relevant\n",
    "new_tweets_df = new_tweets_df[['tweets', 'sentiment', 'sentiment_description']]\n",
    "new_tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting stop words\n",
    "\n",
    "Given that we are aiming to make a Sentiment Analysis, we don't want to remove the negative stopwords because it could impact our detection of any negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use NLTK - Loading stop words and removing negative stop words from the list\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "keep_these_words = ['don', \"don't\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'no', 'nor', 'not', 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "our_stop_words = stop_words\n",
    "for word in keep_these_words:\n",
    "    our_stop_words.remove(word)\n",
    "\n",
    "our_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stop_words(tweet):\n",
    "    tokens = word_tokenize(tweet)\n",
    "    tweet_with_no_stop_words = [token for token in tokens if not token in our_stop_words]\n",
    "    reformed_tweet = ' '.join(tweet_with_no_stop_words)\n",
    " \n",
    "    return reformed_tweet\n",
    "\n",
    "\n",
    "new_tweets_df['tweets'] = new_tweets_df['tweets'].apply(lambda x: remove_stop_words(x))\n",
    "new_tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.regexp import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_tweets_df['tweets_token'] = new_tweets_df['tweets'].apply(lambda x:regexp_tokenize(x,pattern='\\s+',gaps=True))\n",
    "new_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets_df['tweets_length'] = new_tweets_df['tweets_token'].apply(lambda x:len(x))\n",
    "new_tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(new_tweets_df, x=\"tweets_length\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    " \n",
    "all_positive_tweets[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Collections library\n",
    "\n",
    "The Collections module implements high-performance container datatypes (beyond the built-in types list, dict and tuple) and contains many useful data structures that you can use to store information in memory.\n",
    "\n",
    "**Counter()**\n",
    "* A Counter is a container that tracks how many times equivalent values are added.\n",
    "* It can be used to implement the same algorithms for which other languages commonly use bag or multiset data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()\n",
    " \n",
    "\n",
    "for i in range(len(all_positive_tweets)):\n",
    "    for word in all_positive_tweets[i].lower().split(\" \"):\n",
    "        positive_counts[word]+=1\n",
    "        total_counts[word]+=1\n",
    " \n",
    " \n",
    "for i in range(len(all_negative_tweets)):\n",
    "    for word in all_negative_tweets[i].lower().split(\" \"):\n",
    "        negative_counts[word]+=1\n",
    "        total_counts[word]+=1\n",
    "\n",
    "positive_counts.most_common()[0:25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(positive_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.DataFrame(positive_counts.most_common(15), columns=['words', 'count'])\n",
    "positive_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "positive_df.sort_values(by='count').plot.barh(x='words', y='count', ax=ax, color='orange')\n",
    "ax.set_title(\"Frequency of Positive Words - Common Words Found in Tweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_counts.most_common()[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = pd.DataFrame(negative_counts.most_common(15), columns=['words', 'count'])\n",
    "negative_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "negative_df.sort_values(by='count').plot.barh(x='words', y='count', ax=ax, color='green')\n",
    "ax.set_title(\"Frequency of Negative Words - Common Words Found in Tweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 words with the highest Positive Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    " \n",
    "# Calculate the ratios of positive and negative uses of the most common words\n",
    "# Consider words to be \"common\" if they've been used at least 100 times\n",
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "pos_neg_ratios.most_common()[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 words with the highest Positive Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratios.most_common()[::-1][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Understanding the context for each word in our tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "print(pos_tag(tweet_tokens[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list of tags, here is the list of the most common items and their meaning:\n",
    "\n",
    "**NNP:** Noun, proper, singular\n",
    "\n",
    "**NN:** Noun, common, singular or mass\n",
    "\n",
    "**IN:** Preposition or conjunction, subordinating\n",
    "\n",
    "**VBG:** Verb, gerund or present participle\n",
    "\n",
    "**VBN:** Verb, past participle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of removing prefixes and suffixes from words so that they are reduced to simpler forms which are called stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "\n",
    "sentence = [\"We\",\"all\",\"have\",\"fun\", \"when\", \"we\", \"understand\", \"every\", \"topic\", \"given\", \"in\", \"DS4A\"]\n",
    "sentence2 = [\"Totally\", \"locuras\"]\n",
    "porterStemmer = PorterStemmer()\n",
    "\n",
    "print (\" \".join([porterStemmer.stem(word) for word in sentence]))\n",
    "print (\" \".join([porterStemmer.stem(word) for word in sentence2]))\n",
    "\n",
    "# Prints \"thi sentenc wa transform use porter stemmer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lemmatization, the speech part of a word must be determined first and the normalization rules will be different for different parts of the speech, whereas, the stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words that have different meanings depending on part of the speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating tags for each token in the text to Normalize sentences and to lemmatize each word using the tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The function lemmatize_sentence gets the position tag of each token of a tweet.\n",
    "- For example, if the tag starts with NN, the token is assigned as a noun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def lemmatize_sentence(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in pos_tag(tokens):\n",
    "        if tag.startswith('NN'):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatized_sentence\n",
    "\n",
    "print(lemmatize_sentence(tweet_tokens[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why NLP is important?\n",
    "\n",
    "* Human language is astoundingly perplexing and diverse. NLP is an approach that helps us improve our communication and influence skills at a time these are becoming even more important. \n",
    "\n",
    "\n",
    "* In order to make sense of natural language, computers need to listen, process, and analyze human text and speech. \n",
    "\n",
    "\n",
    "* Even though computing systems enable fast and highly accurate communication channels, machines have never been good at understanding how and why we communicate in the first place.\n",
    "\n",
    "\n",
    "*  NLP is significant in light of the fact that it helps settle ambiguity in language and adds valuable numeric structure to the information for some downstream applications, for example, speech recognition or text analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/images/turing__end.png\" alt=\"drawing\" width=\"480\" height=\"320\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
